{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06e361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"D:/Projects/Naive bayes tax evasion/Tax_Evasion.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27039624",
   "metadata": {},
   "source": [
    "This dataset has records of Tax evasion from an XYZ County. Our goal is to establish a ML algorithm to sucessfully classify based on given features wheter a new entrant in database is likely to evade taxes or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ee108",
   "metadata": {},
   "source": [
    "Since our dataset comprises of both continous and categorical(Which will be converted to discrete) features, it is suitable that we use Mixed Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d58d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Refund</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Taxable Income</th>\n",
       "      <th>Evasion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Single</td>\n",
       "      <td>125000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>100000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>70000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>120000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>95000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Refund Marital Status  Taxable Income Evasion\n",
       "Tid                                              \n",
       "1      Yes         Single          125000      No\n",
       "2       No        Married          100000      No\n",
       "3       No         Single           70000      No\n",
       "4      Yes        Married          120000      No\n",
       "5       No       Divorced           95000     Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15115920",
   "metadata": {},
   "source": [
    "Seprating the Target variable from Independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410046e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the features and the target variable\n",
    "X = df.drop('Evasion', axis=1)\n",
    "y = df['Evasion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbccc9",
   "metadata": {},
   "source": [
    "Since Naive Bayes classifiers requires numeric entries we convert our categorical variables to numeric by label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b57efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X['Refund'] = le.fit_transform(X['Refund'])\n",
    "X['Marital Status'] = le.fit_transform(X['Marital Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eadacfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of Refund is: int32, The type of Marital Status is: int32 and the type of y is: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"The type of Refund is: {X['Refund'].dtype}, The type of Marital Status is: {X['Marital Status'].dtype} and the type of y is: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62211a09",
   "metadata": {},
   "source": [
    "Standardizing the continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c96eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X['Taxable Income'] = sc.fit_transform(X[['Taxable Income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a975b",
   "metadata": {},
   "source": [
    "Creating the column transformer to apply different preprocessing on different columns.\n",
    "\n",
    "In our case we our applying our standardization on Taxable income column as it is a continous variable but passing through the two other categorical variables.\n",
    "\n",
    "The two transfomers defined are 'num' and 'cat'. the 'num' is utilizing standard scaler which standardizes the numerical column to have mean 0 and standard deviation 1.  while 'cat' columns are being passed through without any trasnformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7aef0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('num', sc, ['Taxable Income']),\n",
    "                                     ('cat', 'passthrough', ['Refund', 'Marital Status'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e9f4e",
   "metadata": {},
   "source": [
    "Creating the mixed naive bayes pipeline to sequentially apply preprocessing and estimator. \n",
    "\n",
    "In our case our preprocessor is the ct object that we have defined above which standardizes the data and our estimator is GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6407465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', ct),\n",
    "                           ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4bca6",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8560535",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d839d8",
   "metadata": {},
   "source": [
    "Fiting the mixed naive bayes model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2976286",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63160fda",
   "metadata": {},
   "source": [
    "Lastly we would like to see how well our Classifier ML is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a823d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.69      1.00      0.82         9\n",
      "         Yes       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.85      0.67      0.66        15\n",
      "weighted avg       0.82      0.73      0.69        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed4b22",
   "metadata": {},
   "source": [
    "This classification report presents the performance evaluation of a binary classification model on a test set of 15 instances. The model predicts two classes, \"Yes\" and \"No,\" and the report shows performance metrics for each class as well as overall metrics.\n",
    "\n",
    "The precision for the \"No\" class is 0.69, which means that out of all instances predicted as \"No,\" 69% of them were actually \"No.\" The recall for the \"No\" class is 1.0, which means that out of all instances that are actually \"No,\" the model correctly predicted all of them.\n",
    "\n",
    "For the \"Yes\" class, the precision is 1.0, which means that out of all instances predicted as \"Yes,\" all of them were actually \"Yes.\" The recall for the \"Yes\" class is 0.33, which means that out of all instances that are actually \"Yes,\" only 33% of them were correctly predicted by the model.\n",
    "\n",
    "The F1-score is a measure of the model's accuracy that combines precision and recall. The F1-score for the \"No\" class is 0.82, and for the \"Yes\" class, it is 0.5.\n",
    "\n",
    "The accuracy of the model on the test set is 0.73, which means that it correctly predicted 73% of instances. The macro average of precision, recall, and F1-score is calculated as the average of these metrics across both classes, weighted equally. The macro average precision, recall, and F1-score are 0.85, 0.67, and 0.66, respectively. The weighted average of these metrics takes into account the imbalance in class sizes, and the weighted average precision, recall, and F1-score are 0.82, 0.73, and 0.69, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec5247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adeel",
   "language": "python",
   "name": "adeel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
